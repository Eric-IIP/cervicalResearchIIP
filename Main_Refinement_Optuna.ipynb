{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2f91ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters for experiment\n",
    "N_BLOCK = 5\n",
    "LR = 0.001\n",
    "\n",
    "OUTPUT_DIR = '20251204-CorrectionNetworkTestv2.3'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "IN_CHANNEL = 1\n",
    "\n",
    "AUGMENTED = False\n",
    "AUGMENTATION  =  30\n",
    "\n",
    "CROSS_VAL = False\n",
    "N_SPLIT = 4\n",
    "\n",
    "MINE_EPOCH = 25 # start mining after this epoch\n",
    "MAX_MINE_TRAIN = 22\n",
    "MAX_MINE_VAL = 11\n",
    "MIN_ERROR_THRESHOLD = 150  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "beb5a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "from numpy.core.numeric import NaN\n",
    "from MCtool.RFilter import gray\n",
    "from genericpath import exists\n",
    "from matplotlib import image\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.keras.backend import dtype\n",
    "from DeepLearning import LearnAndTest\n",
    "from Rpkg.Rfund.InputFeature import InputFeature\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Rpkg.Rfund import ReadFile, WriteFile\n",
    "from Rpkg.Rmodel import Unet, Mnet\n",
    "\n",
    "import Filtering\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "import DeepLearning\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from Rpkg.Rfund.InputFeature import InputFeature\n",
    "from Rpkg.Rfund import ReadFile, WriteFile\n",
    "from Rpkg.Rmodel import Unet, Mnet\n",
    "\n",
    "from MCtool import RFilter, resultEval\n",
    "from DeepLearning import save_eval_result\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from transformations import ComposeDouble, FunctionWrapperDouble, create_dense_target, normalize_01\n",
    "from customdatasets import SegmentationDataSet1\n",
    "from customdatasets import SegmentationDataSet4\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "from skimage.transform import resize\n",
    "\n",
    "#early stopping ãªã—\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "039dc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## random seed config\n",
    "# Make sure there is no randomness in the output so that the output is reproduceable\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set seed for Python random module\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# If you are using GPU\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Make the convolution operations deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Disable the CUDNN benchmark to ensure deterministic results\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df80a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version installed: 2.3.0+cu121\n",
      "CUDA version associated with PyTorch version: 12.1\n",
      "Version of cuDNN (CUDA Deep Neural Network library) being used by PyTorch8902\n",
      "CUDA is available: True\n",
      "Number of GPUs compatible with CUDA:1\n",
      "Name of the GPU at index 0: NVIDIA GeForce RTX 2080 Ti\n",
      "Current CUDA device index: 0\n"
     ]
    }
   ],
   "source": [
    "## cuda and pytorch stats\n",
    "# è‡ªåˆ†ã®ç’°å¢ƒè¨­å®šãŒã†ã¾ãã„ã£ãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€ç‰¹ã«GPUã®å‹•ä½œ\n",
    "# Prints the version of PyTorch installed\n",
    "print('PyTorch Version installed: ' + torch.__version__)\n",
    "\n",
    "# Prints the version of CUDA associated with the installed PyTorch version\n",
    "print('CUDA version associated with PyTorch version: ' + torch.version.cuda)\n",
    "\n",
    "# Prints the version of cuDNN (CUDA Deep Neural Network library) being used by PyTorch\n",
    "print('Version of cuDNN (CUDA Deep Neural Network library) being used by PyTorch' + str(torch.backends.cudnn.version()))\n",
    "\n",
    "# Same as the line above\n",
    "print('CUDA is available: ' + str(torch.cuda.is_available()))\n",
    "\n",
    "# Returns the number of available CUDA-enabled GPUs\n",
    "print('Number of GPUs compatible with CUDA:' + str(torch.cuda.device_count()))\n",
    "\n",
    "# Returns the name of the GPU at index 0\n",
    "print('Name of the GPU at index 0: '  + str(torch.cuda.get_device_name(0)))\n",
    "\n",
    "# Returns the index of the current CUDA device being used\n",
    "print('Current CUDA device index: '  + str(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b6cfb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file_names_with_prefix\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­éƒ¨åˆ†ï¼ˆprefixï¼‰ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚\n",
    "# å®Ÿéš›ãã‚Œãžã‚Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã¯é•ã†ã¨æ€ã†ã®ã§ã€å¿…é ˆã§ã¯ãªã„\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Extracts filenames in directory if they start with the prefix input \n",
    "\n",
    "\n",
    "Args/Parameters:\n",
    "\n",
    "    directory_path (string): The path of the dir (ex: /root/home/Documents/etc)\n",
    "    \n",
    "    prefix (string): Prefix of the file name (ex: 'Bo' is a prefix of 'Bone')\n",
    "\n",
    "Returns:\n",
    "\n",
    "    sorted_file_names (list of str): File names sorted in ascending order in the dir without extension ex: ['bone1', 'bone2', ...]\n",
    "\n",
    "Raises:\n",
    "\n",
    "    SomeError: ...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def file_names_with_prefix(directory_path, prefix):\n",
    "\n",
    "    # Initialize an empty list to store the file names without extensions\n",
    "    file_names_without_extension = []\n",
    "\n",
    "    # Loop through all files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        #Checking if the file in loop exists in the directory_path not sure how is this necessary\n",
    "        #??\n",
    "        if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "            # Check if the file name starts with the specified prefix\n",
    "            if filename.startswith(prefix):\n",
    "                # Get the file name without extension\n",
    "                name_without_extension, _ = os.path.splitext(filename)\n",
    "\n",
    "                # Append the file name (without extension) to the list\n",
    "                file_names_without_extension.append(name_without_extension)\n",
    "\n",
    "    # Sort the list of file names without extensions in ascending order\n",
    "    sorted_file_names = sorted(\n",
    "        file_names_without_extension,\n",
    "        key=lambda x: (x.split('-')[0], int(x.split('-')[1]))\n",
    "    )  # Modify this part based on your file naming convention\n",
    "\n",
    "    # Now you have a sorted list of file names with the specified prefix and without extensions\n",
    "    return sorted_file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "821fa474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: /home/eric/Documents/cervicalResearchIIP\n",
      "Data directory (original dir): /home/eric/Documents/cervicalResearchIIP/img_1006t/original\n",
      "Feature img directory: /home/eric/Documents/cervicalResearchIIP/img_1006t/feature\n",
      "Labeled img directory: /home/eric/Documents/cervicalResearchIIP/img_1006t/labeled\n",
      "Annealing directory: /home/eric/Documents/cervicalResearchIIP/img_1006/original\n",
      "Result directory: /home/eric/Documents/cervicalResearchIIP/result/20251204-CorrectionNetworkTestv2.3\n",
      "Test result directory: /home/eric/Documents/cervicalResearchIIP/result_test/20251204-CorrectionNetworkTestv2.3\n"
     ]
    }
   ],
   "source": [
    "## paths config\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# ã“ã“ã§ã€folderåã¨ã‹Pathã¨ã‹è‰²ã€…è¨­å®š\n",
    "\n",
    "# Setting the directory name, path and other settings\n",
    "\n",
    "# Define the root directory where your project is located\n",
    "# Defining a Path object for the project's root dir\n",
    "root_dir = Path(pathlib.Path.cwd())\n",
    "\n",
    "# result folder name\n",
    "#date_str = '20241202-Conv1x1-' + str(OUTPUT_DIR)\n",
    "date_str = OUTPUT_DIR\n",
    "\n",
    "# Define the directories for different types of data\n",
    "# Concatenating the root dir to the different dataset dirs\n",
    "data_dir = str(root_dir / \"img_1006t/original\")\n",
    "feature_dir = str(root_dir / \"img_1006t/feature\") \n",
    "labeled_dir = str(root_dir / \"img_1006t/labeled\")\n",
    "\n",
    "augmented_labeled_dir = str(root_dir / \"img_1006t/labelAug\")\n",
    "augmented_data_dir = str(root_dir / \"img_1006t/originalAug\")\n",
    "augmented_feature_dir = str(root_dir / \"img_1006t/featureAug\")\n",
    "\n",
    "\n",
    "# data_dir = str(root_dir / \"img_1006t/MC3x3(108_3out)/mcOriginal\")\n",
    "# feature_dir = str(root_dir / \"img_1006t/MC3x3(108_3out)/mcFeature\") \n",
    "# labeled_dir = str(root_dir / \"img_1006t/labeled\")\n",
    "\n",
    "# augmented_labeled_dir = str(root_dir / \"img_1006t/MC3x3(108_3out)/augMCLabel\")\n",
    "# augmented_data_dir = str(root_dir / \"img_1006t/MC3x3(108_3out)/augMCOriginal\")\n",
    "# augmented_feature_dir = str(root_dir / \"img_1006t/MC3x3(108_3out)/augMCFeature\")\n",
    "\n",
    "# annealing_img_dir = str(root_dir / \"img_1006/annealing_img\") # ç„¼ããªã¾ã—æ³•æ™‚ã«ä½¿ã†\n",
    "# annealing later, original for now\n",
    "annealing_img_dir = str(root_dir / \"img_1006/original\")\n",
    "result_dir = str(root_dir / \"result\" / date_str)\n",
    "test_result_dir= str(root_dir / \"result_test\" / date_str)\n",
    "\n",
    "# Making directories based on the path string result_dir and test_result_dir\n",
    "Path(result_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(test_result_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prints the paths of the dirs\n",
    "print('Root directory: ' + str(root_dir))\n",
    "print('Data directory (original dir): ' + str(data_dir))\n",
    "print('Feature img directory: ' + str(feature_dir))\n",
    "print('Labeled img directory: ' + str(labeled_dir))\n",
    "print('Annealing directory: ' + str(annealing_img_dir))\n",
    "print('Result directory: ' + str(result_dir))\n",
    "print('Test result directory: ' + str(test_result_dir))\n",
    "\n",
    "# Defining variables filename list of path str starts with the prefix format\n",
    "# In this case: N1 and N3 is training data and N2 is validation data and N4 is a test data\n",
    "input_train = []\n",
    "input_name_val = []\n",
    "annealing_input_name = []\n",
    "input_train = []\n",
    "test_input_name = []\n",
    "\n",
    "\n",
    "# for raw_input_img in INPUT:\n",
    "#     input_train.extend(file_names_with_prefix(data_dir, raw_input_img))\n",
    "# for raw_val_img in VALIDATION:\n",
    "#     input_name_val.extend(file_names_with_prefix(data_dir, raw_val_img))\n",
    "# for raw_anneal in ANNEALING:\n",
    "#     annealing_input_name.extend(file_names_with_prefix(data_dir, raw_anneal))\n",
    "# for raw_test in TEST:\n",
    "#     test_input_name.extend(file_names_with_prefix(data_dir, raw_test))\n",
    "\n",
    "\n",
    "####old version of assigning\n",
    "# input_train = file_names_with_prefix(data_dir, INPUT)\n",
    "# input_name_val = file_names_with_prefix(data_dir, VALIDATION)\n",
    "# annealing_input_name = file_names_with_prefix(data_dir, ANNEALING)\n",
    "# test_input_name = file_names_with_prefix(data_dir, TEST) \n",
    "\n",
    "\n",
    "# extra_dataset = file_names_with_prefix(data_dir,'N5-')\n",
    "# input_train.extend(extra_dataset)\n",
    "\n",
    "# Prints the each data image name\n",
    "# print(input_train)\n",
    "# print(input_name_val)\n",
    "# print(annealing_input_name)\n",
    "# print(test_input_name)\n",
    "# print(extra_dataset)\n",
    "\n",
    "\n",
    "# Defining a var to store each list length\n",
    "len_train = len(input_train)\n",
    "len_val = len(input_name_val)\n",
    "len_test = len(test_input_name)\n",
    "len_annealing = len(annealing_input_name)\n",
    "\n",
    "\n",
    "# print(len(input_train))\n",
    "\n",
    "# print(len(input_name_val))\n",
    "# print(len(test_input_name))\n",
    "# print(len(annealing_input_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d84908cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLA_']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## filters\n",
    "# ç‰¹å¾´ç”»åƒã®ç‰¹å¾´ä¸€è¦§ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—#\n",
    "#inputfeature_list = list(map(str, InputFeature))\n",
    "inputfeature_list = ['CLA_']\n",
    "\n",
    "print(inputfeature_list)\n",
    "feature_num = len(inputfeature_list)\n",
    "\n",
    "\n",
    "print(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d4d2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "## createweightimage read by images\n",
    "# takes too much memory cuz it loads all images into np array at once\n",
    "\n",
    "\n",
    "## é‡ã¿è¨ˆç®—ãªã—\n",
    "def CreateWeightImage(input_number, augmentation=False):\n",
    "    print(\"Creating image arrays...\")\n",
    "    label_dataset = []\n",
    "    arrDataset = []\n",
    "    for i in input_number:\n",
    "        if augmentation:\n",
    "            label_path = os.path.join(augmented_labeled_dir, str(AUGMENTATION) + \"aug/\" , f\"{i}.png\")\n",
    "        else:\n",
    "            label_path = os.path.join(labeled_dir, f\"{i}.png\")\n",
    "        input_originallabel = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    \n",
    "        label_dataset.append(input_originallabel)\n",
    "\n",
    "    print(\"Number of label images:\", len(label_dataset))\n",
    "\n",
    "\n",
    "    \n",
    "    for i in input_number:\n",
    "        # changed this part from 100 to 256\n",
    "\n",
    "        dataset_img =  np.zeros((256, 256, feature_num), dtype=np.float32)\n",
    "            \n",
    "            \n",
    "        for m in range(feature_num):\n",
    "            if augmentation:\n",
    "                feature_img_path = os.path.join(augmented_feature_dir, str(AUGMENTATION) + \"aug/\" , str(i), f\"{inputfeature_list[m]}.png\")\n",
    "            else:\n",
    "                feature_img_path = os.path.join(feature_dir, str(i), f\"{inputfeature_list[m]}.png\")\n",
    "            input_featureimg = cv2.imread(feature_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            dataset_img[:, :, m] = input_featureimg\n",
    "\n",
    "        arrDataset.append(dataset_img)\n",
    "\n",
    "    arrDataset = np.array(arrDataset)\n",
    "    print(\"Completed creating image arrays:\")\n",
    "    print(\"Dataset shape \", arrDataset.shape)\n",
    "    print(\"Label image shape \", np.shape(label_dataset))\n",
    "    print()\n",
    "\n",
    "    return arrDataset, label_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "39ee1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "## createweightimagenew read paths only\n",
    "def CreateWeightImageNew(input_numbers, augmentation=False):\n",
    "    print(\"Creating image paths...\")\n",
    "    label_paths = []\n",
    "    feature_paths = []\n",
    "\n",
    "    for i in input_numbers:\n",
    "        if augmentation:\n",
    "            label_path = os.path.join(augmented_labeled_dir, str(AUGMENTATION) + \"aug/\", f\"{i}.png\")\n",
    "        else:\n",
    "            label_path = os.path.join(labeled_dir, f\"{i}.png\")\n",
    "        label_paths.append(label_path)\n",
    "\n",
    "        feature_img_paths = []\n",
    "        for feature_name in inputfeature_list:\n",
    "            if augmentation:\n",
    "                feature_img_path = os.path.join(augmented_feature_dir, str(AUGMENTATION) + \"aug/\", str(i), f\"{feature_name}.png\")\n",
    "            else:\n",
    "                feature_img_path = os.path.join(feature_dir, str(i), f\"{feature_name}.png\")\n",
    "            feature_img_paths.append(feature_img_path)\n",
    "\n",
    "        feature_paths.append(feature_img_paths)\n",
    "\n",
    "    print(f\"Processed {len(label_paths)} label paths and {len(feature_paths)} feature paths.\")\n",
    "    return feature_paths, label_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3a64a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## minor irrelevant function\n",
    "def print_model_shapes(model, input_tensor):\n",
    "    def forward_hook(module, input, output):\n",
    "        print(f\"Layer: {module.__class__.__name__}\")\n",
    "        print(f\"Input shape: {str(input[0].shape)}\")\n",
    "        print(f\"Output shape: {str(output.shape)}\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        hook = layer.register_forward_hook(forward_hook)\n",
    "        hooks.append(hook)\n",
    "\n",
    "    print(\"Model Architecture:\")\n",
    "    print(model)\n",
    "\n",
    "    # Pass a dummy input tensor through the model to trigger the forward hooks\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "13d9d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess and postprocess function\n",
    "def preprocess(img: np.ndarray):\n",
    "    img = np.moveaxis(img, -1, 0)  # Change from [H, W, C] to [C, H, W]\n",
    "    img = normalize_01(img)  # Linear scaling to range [0-1]\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension [B, C, H, W]\n",
    "    img = img.astype(np.float32)  # Typecasting to float32\n",
    "    #print(\"in pre\")\n",
    "    #print(np.unique(img))\n",
    "    return img\n",
    "\n",
    "# postprocess function\n",
    "def postprocess(img: torch.tensor):\n",
    "    img = torch.argmax(img, dim = 1)  # Perform argmax to generate 1 channel\n",
    "    #img = img * 255.0 commented as the labels are from 0 to 11 in my case\n",
    "    img = img.cpu().numpy().astype(np.uint8)  # Send to CPU and transform to numpy.ndarray\n",
    "    # If batch_size > 1, you may need to loop through each batch and save them separately\n",
    "    # If batch_size == 1, you can remove the batch dimension to save a single image\n",
    "\n",
    "    # used for checking the unique label values whether if it is 0 to 11 or 0 to 255 scale\n",
    "    #print(\"in post\")\n",
    "    #print(np.unique(img))\n",
    "\n",
    "\n",
    "    img = np.squeeze(img)  # Remove batch dim and channel dim -> [H, W]\n",
    "    # img = re_normalize(img)  # Scale it to the range [0-255]\n",
    "\n",
    "    # If your image has multiple channels (C>1), like an RGB image, before saving with cv2.imwrite\n",
    "    # you need to ensure the channel order is [B, G, R] instead of the common [R, G, B]\n",
    "    # If C == 1, you can further reduce dimensions -> [H, W]\n",
    "    if img.shape[0] == 3:  # [C, H, W]\n",
    "        img = np.transpose(img, (1, 2, 0))  # [H, W, C]\n",
    "        img = img[:, :, ::-1]  # Convert RGB to BGR\n",
    "    elif img.shape[0] == 1:  # [C, H, W]\n",
    "        img = np.squeeze(img, 0)  # [H, W]\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bc4af485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(training_losses, validation_losses, lr_rates, learning_curve, model, fold, input_dataset_val, input_name_val, type_number, device, model_n = \"unet1\"):\n",
    "    \n",
    "    #logging to csv\n",
    "    assert len(training_losses) == len(validation_losses) == len(lr_rates), \\\n",
    "        \"Lengths of training, validation losses, and learning rates must match.\"\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        \"Epoch\": list(range(1, len(training_losses) + 1)),\n",
    "        \"Training_Loss\": training_losses,\n",
    "        \"Validation_Loss\": validation_losses,\n",
    "        \"Learning_Rate\": lr_rates\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(test_result_dir + f\"/{model_n}_fold{fold}_log.csv\", index = False)\n",
    "    \n",
    "    learning_curve.savefig(test_result_dir + f\"/{model_n}_fold{fold}_learningcurve.png\")\n",
    "    \n",
    "    print(\"***************************\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ã“ã“ãŒã¡ã‚ƒã‚“ã¨ESã§æœ€é©ãªã‚¨ãƒãƒƒã‚¯æ•°ã®ãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã‚‹ã‹è¦æ¤œè¨¼\n",
    "    model_dir = os.path.join(\"model\", date_str)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_name = f\"{model_n}_fold_{fold}.pt\"\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"modelname:{model_name}ã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "    #torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "    model_weights = torch.load(model_path)\n",
    "    model.load_state_dict(model_weights)\n",
    "    \n",
    "    \n",
    "\n",
    "    # images = annealing_input_dataset\n",
    "    images = input_dataset_val\n",
    "\n",
    "    from inference import predict\n",
    "    from transformations import normalize_01, re_normalize\n",
    "    # predict the segmentation maps \n",
    "    # output = [predict(img, model, preprocess, postprocess, device) for img in images]\n",
    "\n",
    "\n",
    "    # for i in range(len(input_name_val)):\n",
    "    #     if(type_number == 0):\n",
    "    #         cv2.imwrite(os.path.join(result_dir, f'{model_n}_{input_name_val[i]}.png'), output[i])\n",
    "    #     elif(type_number == 1):\n",
    "    #         cv2.imwrite(os.path.join(test_result_dir, 'result_original', f'{input_name_val[i]}.png'), output[i])\n",
    "    #     elif(type_number == 2):\n",
    "    #         cv2.imwrite(os.path.join(test_result_dir, 'result_test', f'{input_name_val[i]}.png'), output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "be2391b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## learn_ea function training logic\n",
    "# earlystoppingã‚ã‚Š\n",
    "# numpyå½¢å¼ã®ã¾ã¾å…¥åŠ›ã™ã‚‹ç”¨æ”¹è‰¯\n",
    "# å­¦ç¿’ã‚’è¡Œã„äºˆæ¸¬çµæžœç”»åƒã‚’å‡ºåŠ›ã™ã‚‹ã¨ã“ã¾ã§\n",
    "from customdatasets import SegmentationDataSet0\n",
    "from customdatasets import SegmentationDataSet1\n",
    "from customdatasets import SegmentationDataSet5\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def Learn_EA(input_dataset,label_dataset,input_dataset_val,label_dataset_val, type_number, fold=0, next_model = False, model_n = \"unet1\", inChannels = 1):\n",
    "    print(\"*************************Training*************************\")\n",
    "    # å¼•æ•°ã‚’è¿½åŠ ã—ã¦ä¿å­˜å…ˆã‚’æŒ‡å®šã™ã‚‹ã‚ˆã†æ”¹è‰¯\n",
    "    # try_number:ä½•å›žç›®ã®ç„¼ããªã¾ã—ã‹ã©ã†ã‹ã€‚ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«ä½¿ç”¨\n",
    "\n",
    "\n",
    "    if next_model is False:\n",
    "        \n",
    "        dataset_train2 = SegmentationDataSet0(\n",
    "            inputs=input_dataset,        # train_preds\n",
    "            targets=label_dataset,       # train_targets\n",
    "            transform=None\n",
    "        )\n",
    "\n",
    "        dataset_val = SegmentationDataSet0(\n",
    "            inputs=input_dataset_val,    # val_preds\n",
    "            targets=label_dataset_val,   # val_targets\n",
    "            transform=None\n",
    "    )\n",
    "    else:\n",
    "\n",
    "        dataset_train2 = SegmentationDataSet0(\n",
    "            inputs=input_dataset,        # original images\n",
    "            targets=label_dataset,       # GT masks\n",
    "            transform=transforms_training\n",
    "        )\n",
    "\n",
    "        dataset_val = SegmentationDataSet0(\n",
    "            inputs=input_dataset_val,    # original validation images\n",
    "            targets=label_dataset_val,   # GT masks\n",
    "            transform=transforms_val\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    dataloader_training2 = DataLoader(dataset=dataset_train2,\n",
    "                                        batch_size = 2,\n",
    "                                        shuffle=True)\n",
    "                                        #num_workers=4,\n",
    "                                        #pin_memory=True)\n",
    "        #ã‚‚ã¨ã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«true\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    batch = next(iter(dataloader_training2))\n",
    "  \n",
    "    x, y = batch\n",
    "    print(\"x.shape = \", x.shape)\n",
    "    print(\"x.min(), x.max() = \", x.min(), x.max())\n",
    "    print(\"y.shape = \", y.shape)\n",
    "    print(\"torch.unique(y) = \", torch.unique(y))\n",
    "\n",
    "\n",
    "    \n",
    "    # # dataset training\n",
    "    # dataset_val = SegmentationDataSet0(inputs=input_dataset_val,\n",
    "    #                                     targets=label_dataset_val,\n",
    "    #                                     transform=transforms_val)\n",
    "    # if next_model==False:\n",
    "    #     dataset_val = SegmentationDataSet0(inputs=input_dataset_val,\n",
    "    #                                     targets=label_dataset_val,\n",
    "    #                                     transform=None)\n",
    "        \n",
    "    #æ›¸ãæ›ãˆç®‡æ‰€\n",
    "    dataloader_val = DataLoader(dataset=dataset_val,\n",
    "                                     batch_size = 2,\n",
    "                                     shuffle=False)\n",
    "                                     #num_workers=4, # for faster training loads next batch while training\n",
    "                                     #pin_memory=True)  # for faster training, keeps data in pinned memory\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###earlystopping ã‚ã‚Š\n",
    "\n",
    "    from unet import UNet\n",
    "    from trainer2 import Trainer2 \n",
    "    from torch import nn #import torch \n",
    "    from pytorchtools import EarlyStopping\n",
    "    from torch.nn import BCEWithLogitsLoss\n",
    "    from customLoss import DiceCELoss\n",
    "    from customLoss import DiceLoss\n",
    "    from customLoss import ExponentialLogCE_DiceLoss\n",
    "    from customLoss import EnsembleInspiredLoss\n",
    "    from customLoss import ConfusionPenaltyLoss\n",
    "    from customLoss import CombinedLoss\n",
    "\n",
    "    #device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda') \n",
    "    else: \n",
    "        torch.device('cpu')\n",
    "        print(\"Before creating the UNet model: GPU was not available and CPU will be used instead\")\n",
    "\n",
    "    # custom logging the parameters of the UNet\n",
    "    inChannels = inChannels\n",
    "    outChannels = 11\n",
    "    nBlocks = N_BLOCK\n",
    "    startFilters = 32\n",
    "\n",
    "    from customLog import custom_logger\n",
    "    \n",
    "    #custom_logger(\"/log/customLog.log\", inChannels, outChannels, nBlocks, startFilters)\n",
    "\n",
    "    #model\n",
    "    model = UNet(in_channels = inChannels,\n",
    "                 out_channels = outChannels,\n",
    "                 n_blocks = nBlocks, \n",
    "                 start_filters=32,\n",
    "                 activation='relu',\n",
    "                 normalization='instance',\n",
    "                 conv_mode='same',\n",
    "                 dim=2,\n",
    "                 ).to(device)\n",
    "    \n",
    "    # printing parameter name of the model could be done for criterion too\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(name, param.device, param.requires_grad)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # Assuming input_tensor is a sample input tensor with the correct shape (e.g., torch.randn(1, 3, 100, 100))\n",
    "    input_tensor = torch.randn(1, 45, 100, 100).to(device)  # Adjust the shape as needed\n",
    "    # print_model_shapes(model, input_tensor)\n",
    "\n",
    "    from customLoss import BoundaryDiceLoss\n",
    "\n",
    "    from customLoss import BoundaryIOU\n",
    "    from customLoss import BoundaryDiceLoss\n",
    "    from customLoss import FocalLoss\n",
    "    from customLoss import CombinedLossV2\n",
    "    from customLoss import CombinedLoss\n",
    "    from customLoss import DiceLoss\n",
    "    from customLoss import EnsembleInspiredLoss\n",
    "    from customLoss import HausdorffLoss\n",
    "    from customLoss import JointCELossHausdorff\n",
    "\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    #optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    #trainer\n",
    "    trainer = Trainer2(model=model, \n",
    "                       device=device, \n",
    "                       criterion=criterion, \n",
    "                       optimizer=optimizer, \n",
    "                       training_DataLoader=dataloader_training2,\n",
    "                       #validation_DataLoader=None, \n",
    "                       validation_DataLoader=dataloader_val, \n",
    "                       lr_scheduler=None, \n",
    "                       epochs=200, ##ðŸ˜ºðŸ˜ºðŸ˜ºðŸ˜º epoch=0, \n",
    "                       notebook=True,\n",
    "                       mine_epoch = MINE_EPOCH,\n",
    "                       max_mine_train = MAX_MINE_TRAIN,\n",
    "                       max_mine_val = MAX_MINE_VAL,\n",
    "                       min_error_threshold = MIN_ERROR_THRESHOLD\n",
    "                       )\n",
    "    print(\"=======start training======\")\n",
    "    \n",
    "    # start training\n",
    "    #for combined\n",
    "    training_losses, validation_losses, lr_rates, learning_curve, train_preds, train_targets, val_preds, val_targets = trainer.run_trainer()\n",
    "    trainer.plot_mined_samples(n=10, split='train')\n",
    "    trainer.plot_mined_samples(n=10, split='val')\n",
    "    \n",
    "\n",
    "    def safe_cat(tensors):\n",
    "        if isinstance(tensors, torch.Tensor):\n",
    "            return tensors  # already a tensor\n",
    "        if len(tensors) == 0:\n",
    "            raise RuntimeError(\"No predictions collected.\")\n",
    "        return torch.cat(tensors, dim=0)\n",
    "\n",
    "    train_preds = safe_cat(train_preds)  # [N, C, H, W]\n",
    "    train_targets = safe_cat(train_targets)  # [N, H, W]\n",
    "\n",
    "    val_preds = safe_cat(val_preds)\n",
    "    val_targets = safe_cat(val_targets)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    record_results(training_losses, validation_losses, lr_rates, learning_curve, model, fold, input_dataset_val, input_name_val, type_number, device, model_n)\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    # Clear CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Optionally reset max memory tracking\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    if next_model == False:\n",
    "        return\n",
    "    \n",
    "    inChannels = 11\n",
    "    \n",
    "    return Learn_EA(train_preds, train_targets, val_preds, val_targets, type_number, fold, next_model = False, model_n=\"unet2\", inChannels=11)\n",
    "    \n",
    "    # #logging to csv\n",
    "    # assert len(training_losses) == len(validation_losses) == len(lr_rates), \\\n",
    "    #     \"Lengths of training, validation losses, and learning rates must match.\"\n",
    "\n",
    "    # # Create dataframe\n",
    "    # df = pd.DataFrame({\n",
    "    #     \"Epoch\": list(range(1, len(training_losses) + 1)),\n",
    "    #     \"Training_Loss\": training_losses,\n",
    "    #     \"Validation_Loss\": validation_losses,\n",
    "    #     \"Learning_Rate\": lr_rates\n",
    "    # })\n",
    "\n",
    "    # # Save to CSV\n",
    "    # df.to_csv(test_result_dir + f\"/fold{fold}_log.csv\", index = False)\n",
    "    \n",
    "    # learning_curve.savefig(test_result_dir + f\"/fold{fold}_learningcurve.png\")\n",
    "    \n",
    "    # print(\"***************************\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # #ã“ã“ãŒã¡ã‚ƒã‚“ã¨ESã§æœ€é©ãªã‚¨ãƒãƒƒã‚¯æ•°ã®ãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã‚‹ã‹è¦æ¤œè¨¼\n",
    "    # model_dir = os.path.join(\"model\", date_str)\n",
    "    # if not os.path.exists(model_dir):\n",
    "    #     os.makedirs(model_dir)\n",
    "    # model_name = f\"model_fold_{fold}.pt\"\n",
    "    # model_path = os.path.join(model_dir, model_name)\n",
    "    # torch.save(model.state_dict(), model_path)\n",
    "    # print(f\"modelname:{model_name}ã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "    # #torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "    # model_weights = torch.load(model_path)\n",
    "    # model.load_state_dict(model_weights)\n",
    "    \n",
    "    \n",
    "\n",
    "    # # images = annealing_input_dataset\n",
    "    # images = input_dataset_val\n",
    "\n",
    "    # from inference import predict\n",
    "    # from transformations import normalize_01, re_normalize\n",
    "    # # predict the segmentation maps \n",
    "    # output = [predict(img, model, preprocess, postprocess, device) for img in images]\n",
    "\n",
    "\n",
    "    # for i in range(len(input_name_val)):\n",
    "    #     if(type_number == 0):\n",
    "    #         cv2.imwrite(os.path.join(result_dir, f'{input_name_val[i]}.png'), output[i])\n",
    "    #     elif(type_number == 1):\n",
    "    #         cv2.imwrite(os.path.join(test_result_dir, 'result_original', f'{input_name_val[i]}.png'), output[i])\n",
    "    #     elif(type_number == 2):\n",
    "    #         cv2.imwrite(os.path.join(test_result_dir, 'result_test', f'{input_name_val[i]}.png'), output[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "99dfe248",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dice calculation\n",
    "import statistics\n",
    "# Dicecã®è¨ˆç®—\n",
    "def cal_DiceMulitple(dir, input_name):\n",
    "    # change the label count as your preference\n",
    "    Dice = [0] * 11\n",
    "    Count1 = [0] * 11 #äºˆæ¸¬çµæžœã®å„ãƒ©ãƒ™ãƒ«ã®è¦ç´ æ•°\n",
    "    Count2 = [0] * 11 #ãƒ©ãƒ™ãƒ«ç”»åƒã®\n",
    "    Count3 = [0] * 11 #æ­£è§£ã—ãŸç”»ç´ æ•°\n",
    "    \n",
    "    for index in range(len(input_name)):\n",
    "        print('index = ', index)\n",
    "\n",
    "        img1 = cv2.imread(dir + '/' + input_name[index] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(labeled_dir + '/' + input_name[index] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "        #_, img2 = cv2.threshold(img2, 0, 255, cv2.THRESH_BINARY)\n",
    "        print(\"äºˆæ¸¬ç”»åƒ:\", dir  + '/' + input_name[index] + \".png\")\n",
    "        print(\"ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«:\", labeled_dir + '/' + input_name[index] + \".png\")\n",
    "        unique_label1 = np.unique(img1)\n",
    "        unique_label2 = np.unique(img2)\n",
    "        # print(unique_label1)\n",
    "        # print(unique_label2)\n",
    "        # change the image array size to your need\n",
    "        for n in range(256):\n",
    "            for l in range(256):\n",
    "                value1 = img1[n,l]\n",
    "                # for index, uq_value in enumerate(unique_label1):\n",
    "                #     if(value1 == uq_value):\n",
    "                #         value1 = index\n",
    "\n",
    "                Count1[value1] += 1\n",
    "\n",
    "                value2 = img2[n,l]\n",
    "                Count2[value2] += 1                    \n",
    "\n",
    "                if(value1 == value2):\n",
    "                    Count3[value1] += 1 \n",
    "    for i in range(11):\n",
    "        if(Count1[i]+Count2[i] != 0):\n",
    "            Dice[i] = (2*Count3[i])/(Count1[i] + Count2[i])\n",
    "        if(Count1[i]+Count2[i] == 0):\n",
    "            print(\"\")\n",
    "            #print(\"4 label case:\" + str(input_name[index]))\n",
    "    Dice.append(statistics.mean(Dice[1:]))\n",
    "    print('Count1 = ', Count1)\n",
    "    print('Count2 = ', Count2)\n",
    "    print('Count3 = ', Count3)\n",
    "    print('Dice = ', Dice)\n",
    "    #print(unique_label)\n",
    "\n",
    "    return Dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89ab1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## mConv_predict test function\n",
    "import statistics\n",
    "from inference import predict\n",
    "from denseCRF import noiseReduction\n",
    "# device\n",
    "def mConv_predict(test_input_name, fold=0):\n",
    "    print(\"*************************************Test*************************************\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ---------- Load Models ----------\n",
    "    model_dir = os.path.join(\"model\", date_str)\n",
    "    model1_path = os.path.join(model_dir, f\"unet1_fold_{fold}.pt\")\n",
    "    model2_path = os.path.join(model_dir, f\"unet2_fold_{fold}.pt\")\n",
    "\n",
    "    model1 = UNet(in_channels=IN_CHANNEL,  # check the parameters\n",
    "            out_channels=11,\n",
    "            n_blocks=N_BLOCK,\n",
    "            start_filters=32,\n",
    "            activation='relu',\n",
    "            normalization='instance', #use instance when \"batch\" size is less than 10? batch\n",
    "            conv_mode='same',\n",
    "            dim=2).to(device)\n",
    "    \n",
    "    model2 = UNet(in_channels=11,  # check the parameters\n",
    "            out_channels=11,\n",
    "            n_blocks=N_BLOCK,\n",
    "            start_filters=32,\n",
    "            activation='relu',\n",
    "            normalization='instance', #use instance when \"batch\" size is less than 10? batch\n",
    "            conv_mode='same',\n",
    "            dim=2).to(device)\n",
    "\n",
    "\n",
    "    model1.load_state_dict(torch.load(model1_path))\n",
    "    model2.load_state_dict(torch.load(model2_path))\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    # ---------- Load Test ----------\n",
    "    test_input_dataset, _ = CreateWeightImage(test_input_name)\n",
    "\n",
    "    output_stage1 = []\n",
    "    output_stage2 = []\n",
    "\n",
    "    # ---------- Stage-1 + Stage-2 ----------\n",
    "    with torch.no_grad():\n",
    "        for img in test_input_dataset:\n",
    "            result1, prob1, pred1 = predict(img, model1, preprocess, postprocess, device)\n",
    "\n",
    "            # Save stage-1 output (mask form)\n",
    "            output_stage1.append(pred1)\n",
    "\n",
    "            # prob1 shape: [1,11,H,W] â†’ correct Stage-2 input\n",
    "            prob1 = prob1.to(device)  \n",
    "            out2 = model2(prob1)\n",
    "            pred2 = torch.argmax(out2, 1).squeeze().cpu().numpy()\n",
    "            output_stage2.append(pred2)\n",
    "\n",
    "    # ---------- Save results ----------\n",
    "    fold_dir = os.path.join(test_result_dir, f\"fold{fold}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "    unet1_dir = os.path.join(fold_dir, \"unet1\")\n",
    "    unet2_dir = os.path.join(fold_dir, \"unet2\")\n",
    "    os.makedirs(unet1_dir, exist_ok=True)\n",
    "    os.makedirs(unet2_dir, exist_ok=True)\n",
    "\n",
    "    for i, name in enumerate(test_input_name):\n",
    "        cv2.imwrite(os.path.join(unet1_dir, f\"{name}.png\"), output_stage1[i])\n",
    "        cv2.imwrite(os.path.join(unet2_dir, f\"{name}.png\"), output_stage2[i])\n",
    "\n",
    "    # ---------- Dice + CRF ----------\n",
    "    Dice1 = cal_DiceMulitple(unet1_dir, test_input_name)\n",
    "    Dice2 = cal_DiceMulitple(unet2_dir, test_input_name)\n",
    "    pd.DataFrame(Dice1).T.to_csv(f\"{test_result_dir}/unet1Dice.csv\", mode='a', header=False)\n",
    "    pd.DataFrame(Dice2).T.to_csv(f\"{test_result_dir}/unet2Dice.csv\", mode='a', header=False)\n",
    "\n",
    "    postCRF1 = noiseReduction(output_stage1, test_input_name, labeled_dir, unet1_dir, 0.8)\n",
    "    postCRF2 = noiseReduction(output_stage2, test_input_name, labeled_dir, unet2_dir, 0.8)\n",
    "\n",
    "    DiceCRF1 = cal_DiceMulitple(unet1_dir + \"/crf\", test_input_name)\n",
    "    DiceCRF2 = cal_DiceMulitple(unet2_dir + \"/crf\", test_input_name)\n",
    "    pd.DataFrame(DiceCRF1).T.to_csv(f\"{test_result_dir}/unet1CRFDice.csv\", mode='a', header=False)\n",
    "    pd.DataFrame(DiceCRF2).T.to_csv(f\"{test_result_dir}/unet2CRFDice.csv\", mode='a', header=False)\n",
    "    \n",
    "    df1 = pd.DataFrame([Dice1])\n",
    "    df2 = pd.DataFrame([Dice2])\n",
    "\n",
    "    # Get last column value\n",
    "    last_val1 = df1.iloc[0, -1]\n",
    "    last_val2 = df2.iloc[0, -1]\n",
    "\n",
    "    return last_val1, last_val2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7be8994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "STUDY_NAME = \"unet_stage2\"\n",
    "DB_PATH = \"sqlite:///unet_optuna.db\"\n",
    "BEST_JSON_PATH = \"best_trial.json\"\n",
    "LOG_PATH = \"training_log.txt\"\n",
    "\n",
    "def log(msg: str):\n",
    "    print(msg)\n",
    "    with open(LOG_PATH, \"a\") as f:\n",
    "        f.write(msg + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8ba9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataArrange import dataRearrange1\n",
    "## Test Learn_EA without annealing\n",
    "# training transformations and augmentations\n",
    "\n",
    "transforms_training = ComposeDouble([\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "#è¿½åŠ ç®‡æ‰€ver3\n",
    "transforms_val =  ComposeDouble([\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "\n",
    "])\n",
    "def execute():\n",
    "    ## Execution\n",
    "\n",
    "\n",
    "\n",
    "    # random seed\n",
    "    random_seed = 0\n",
    "\n",
    "    X = file_names_with_prefix(data_dir, 'N')\n",
    "\n",
    "    y_file_names = file_names_with_prefix(labeled_dir, 'N')\n",
    "\n",
    "\n",
    "    # removal = [\"N1-2\", \"N1-4\", \"N5-6\", \"N2-9\"]\n",
    "    # X = [item for item in X if item not in removal]\n",
    "    # y_file_names = [item for item in y_file_names if item not in removal]\n",
    "\n",
    "    y = [label_group[:2] for label_group in y_file_names]\n",
    "\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "\n",
    "    print(X)\n",
    "    print(y)\n",
    "\n",
    "\n",
    "\n",
    "    if CROSS_VAL:\n",
    "        skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True)\n",
    "        # each case same division\n",
    "        #skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=42)\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "            # if fold == 1:\n",
    "            #      continue\n",
    "            # Split the data into train and test sets\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # Split the training data further into train and validation ( 1/3 split)\n",
    "            X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "                X_train, y_train, test_size=0.333333333, random_state=42, stratify=y_train)\n",
    "            \n",
    "            \n",
    "            input_train = X_train_final\n",
    "            input_name_val = X_val\n",
    "            print(\"Cross validation: \" + str(CROSS_VAL))\n",
    "            print(f\"Fold: {fold} out of {N_SPLIT}\")\n",
    "            print(\"Augmentation: \" + str(AUGMENTED))\n",
    "            if AUGMENTED:\n",
    "                print(\"Augmentation amount: \" + str(AUGMENTATION))\n",
    "            print(\"Training: Total of \" + str(len(input_train)) + \" cases.\")\n",
    "            print(input_train)\n",
    "\n",
    "            print(\"Validation: Total of \" + str(len(input_name_val)) + \" cases.\")\n",
    "            print(input_name_val)\n",
    "            \n",
    "            print(\"Test: Total of \" + str(len(X_test)) + \" cases.\")  \n",
    "            print(X_test)\n",
    "            print()\n",
    "            \n",
    "            if AUGMENTED:\n",
    "                ## This part is for accounting the data augmentation, attaches augmentation numbers after the original img\n",
    "                ## ex: original number N1-1 -> N1-1-1, N1-1-2 etc.\n",
    "                repeated_items_train = np.repeat(input_train, AUGMENTATION)\n",
    "                suffixes_train = np.tile(np.arange(1, AUGMENTATION + 1), len(repeated_items_train))\n",
    "                input_train = np.array([f\"{item}-{suffix}\" for item, suffix in zip(repeated_items_train, suffixes_train)])\n",
    "                #Custom Arranging for training dataset because of the augmentation order\n",
    "                input_train = np.array(dataRearrange1(input_train, AUGMENTATION))\n",
    "                \n",
    "                \n",
    "                repeated_items_val = np.repeat(input_name_val, AUGMENTATION)\n",
    "                suffixes_val = np.tile(np.arange(1, AUGMENTATION + 1), len(repeated_items_val))\n",
    "                input_name_val = np.array([f\"{item}-{suffix}\" for item, suffix in zip(repeated_items_val, suffixes_val)])\n",
    "            \n",
    "            \n",
    "            #input_dataset,label_dataset = CreateWeightImageNew(input_train, augmentation=AUGMENTED)\n",
    "            input_dataset,label_dataset = CreateWeightImage(input_train, augmentation=AUGMENTED)\n",
    "            input_dataset_val,label_dataset_val = CreateWeightImage(input_name_val, augmentation=AUGMENTED)\n",
    "            \n",
    "            \n",
    "            Learn_EA(input_dataset,label_dataset,input_dataset_val,label_dataset_val, 0, fold, next_model=True)\n",
    "            mConv_predict(X_test, fold)\n",
    "            \n",
    "            # Force garbage collection \n",
    "            gc.collect()\n",
    "\n",
    "            # Clear CUDA memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Optionally reset max memory tracking\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=RANDOM_SEED)\n",
    "        \n",
    "        X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "                X_train, y_train, test_size=0.333333333, random_state=42, stratify=y_train)\n",
    "        \n",
    "        input_train = X_train_final\n",
    "        input_name_val = X_val\n",
    "        \n",
    "        print(\"Cross validation: \" + str(CROSS_VAL))\n",
    "        print(\"Augmentation: \" + str(AUGMENTED))\n",
    "        if AUGMENTED:\n",
    "            print(\"Augmentation amount: \" + str(AUGMENTATION))\n",
    "        print(\"Training: Total of \" + str(len(input_train)) + \" cases.\")\n",
    "        print(input_train)\n",
    "\n",
    "        print(\"Validation: Total of \" + str(len(input_name_val)) + \" cases.\")\n",
    "        print(input_name_val)\n",
    "            \n",
    "        print(\"Test: Total of \" + str(len(X_test)) + \" cases.\")  \n",
    "        print(X_test)\n",
    "        print()\n",
    "        \n",
    "        if AUGMENTED:\n",
    "            ## This part is for accounting the data augmentation, attaches augmentation numbers after the original img\n",
    "            ## ex: original number N1-1 -> N1-1-1, N1-1-2 etc.\n",
    "            repeated_items_train = np.repeat(input_train, AUGMENTATION)\n",
    "            suffixes_train = np.tile(np.arange(1, AUGMENTATION + 1), len(repeated_items_train))\n",
    "            input_train = np.array([f\"{item}-{suffix}\" for item, suffix in zip(repeated_items_train, suffixes_train)])\n",
    "            \n",
    "            #Custom Arranging for training dataset because of the augmentation order\n",
    "            input_train = np.array(dataRearrange1(input_train, AUGMENTATION))\n",
    "                \n",
    "                \n",
    "            repeated_items_val = np.repeat(input_name_val, AUGMENTATION)\n",
    "            suffixes_val = np.tile(np.arange(1, AUGMENTATION + 1), len(repeated_items_val))\n",
    "            input_name_val = np.array([f\"{item}-{suffix}\" for item, suffix in zip(repeated_items_val, suffixes_val)])\n",
    "        \n",
    "        input_dataset,label_dataset = CreateWeightImage(input_train, augmentation=AUGMENTED)\n",
    "        input_dataset_val,label_dataset_val = CreateWeightImage(input_name_val, augmentation=AUGMENTED)\n",
    "        \n",
    "        Learn_EA(input_dataset,label_dataset,input_dataset_val,label_dataset_val, 0, next_model=True)\n",
    "        dice1, dice2 = mConv_predict(X_test)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "        # Clear CUDA memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Optionally reset max memory tracking\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "    return dice1, dice2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0b4c0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    try:\n",
    "        # Hyperparameters for Optuna to explore\n",
    "        \n",
    "        MINE_EPOCH = trial.suggest_int(\"mine_epoch\", 10, 40)\n",
    "        MIN_ERROR_THRESHOLD = trial.suggest_int(\"min_error_threshold\", 200, 1000)\n",
    "\n",
    "        # -----------------\n",
    "        # TRAINING CALL\n",
    "        # -----------------\n",
    "        dice1, dice2 = execute()\n",
    "        trial.set_user_attr(\"dice1\", dice1)\n",
    "\n",
    "        log(f\"Trial {trial.number} | \"\n",
    "            f\"DICE1={dice1:.4f} | \"\n",
    "            f\"DICE2={dice2:.4f} | \"\n",
    "            f\"params={trial.params}\")\n",
    "\n",
    "        return dice2\n",
    "\n",
    "    except Exception:\n",
    "        err = traceback.format_exc()\n",
    "        log(f\"Trial {trial.number} FAILED\\n{err}\")\n",
    "        # Fail gracefully and continue study\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "267f344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-04 22:20:02,509] Using an existing study with name 'unet_stage2' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046ec013880e44a88cfff9c9ace701af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d398392687a541f68aaccecd05074123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aae57b8ac804909a5ddb5d83501cfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f504df5014374fac84ae766d7b30098e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d995599a6da456ca0c2fc9dafd017e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470c2a1b33774a83b2ca6cd503a94b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ab246fa1534519997716c3aff4f3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4ece3acf8f46669cf14ca1798a81ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7444182525d34dbe83e9e9bbff23301c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65e20f1d45e4b8eadd620c6816aeb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1b6ee14cfb4077a5c55c34d877e759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4893e886ea2a409c9c1df6b5a670c764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62438fb26d594e7abf70b551759dd5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35bfda6b5124062a1ac4ff73e6bdf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbda063dc1554fec98c8b5688fa791ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c59dc86c33f4f7c8299ec5f75952043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771966e5e95b42aa913c42eef08935e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a306cce2c74b3daca63eeb14d50cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeb798a93c14b4081aaea4f4eb9a1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde54d20243d413a83559de051edcaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfa11e6fba94678ba108bd354fcbeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3762b4e53a9f46fa832cfde7b1fe466d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3759af1d72ce4fe78e1353cebd821a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7687ebd8af3140228389437fd4911d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1269d3e6a6f648678b30fa6152917b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68f6b9fe897428d80952a5a510acf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c39525dca443e59161cf29e1e8ab6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9948e5f5cb4092a6ac6760c61649fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7141301818594f6dbaf85559a9d0e71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fd499322a443c38c3d6bdfc7386393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a92e24ada3940eb88314929ff9cd534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8379b7eba55748d688ab8a0932065c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f185fa63f9493792690f3a98bc6e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d93662113346fbaf0bbdf3d1f0a0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34a87f0d61c4879bb96e26833d39240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bceaa718144388a40fa392ced058a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9572482f80d04ac6b9bb56e2c29734d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333093d55f9e457990b82709cca09738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2a2b37965144169c74b45c7028cca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-12-04 22:20:14,252] Trial 1 failed with parameters: {'mine_epoch': 17, 'min_error_threshold': 860} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3631502/4076041273.py\", line 11, in objective\n",
      "    dice1, dice2 = execute()\n",
      "                   ^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3631502/2716774100.py\", line 154, in execute\n",
      "    Learn_EA(input_dataset,label_dataset,input_dataset_val,label_dataset_val, 0, next_model=True)\n",
      "  File \"/tmp/ipykernel_3631502/3968670307.py\", line 175, in Learn_EA\n",
      "    training_losses, validation_losses, lr_rates, learning_curve, train_preds, train_targets, val_preds, val_targets = trainer.run_trainer()\n",
      "                                                                                                                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eric/Documents/cervicalResearchIIP/trainer2.py\", line 197, in run_trainer\n",
      "    early_stopping(self.validation_loss[i],self.model)\n",
      "  File \"/home/eric/Documents/cervicalResearchIIP/pytorchtools.py\", line 43, in __call__\n",
      "    self.save_checkpoint(val_loss, model)\n",
      "  File \"/home/eric/Documents/cervicalResearchIIP/pytorchtools.py\", line 50, in save_checkpoint\n",
      "    torch.save(model.state_dict(), self.path)\n",
      "  File \"/home/eric/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/serialization.py\", line 628, in save\n",
      "    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n",
      "  File \"/home/eric/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/serialization.py\", line 862, in _save\n",
      "    zip_file.write_record(name, storage, num_bytes)\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-04 22:20:14,254] Trial 1 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "tqdm.disable = True\n",
    "with open(\"train.log\", \"a\") as log_file:\n",
    "    with contextlib.redirect_stdout(log_file), \\\n",
    "         contextlib.redirect_stderr(log_file):\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            study_name=STUDY_NAME,\n",
    "            direction=\"maximize\",\n",
    "            storage=DB_PATH,\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            study.optimize(objective, n_trials=200)\n",
    "        except KeyboardInterrupt:\n",
    "            log(\"=== INTERRUPTED BY USER ===\")\n",
    "        finally:\n",
    "            log(\"=== OPTUNA FINISHED ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial = 0\n",
      "Best DICE2 = 0.5766\n",
      "Best DICE1 = 0.6578\n",
      "Best Params = {'mine_epoch': 10, 'min_error_threshold': 857}\n"
     ]
    }
   ],
   "source": [
    "# Save best trial information\n",
    "best = study.best_trial\n",
    "log(f\"Best Trial = {best.number}\")\n",
    "log(f\"Best DICE2 = {best.value:.4f}\")\n",
    "log(f\"Best DICE1 = {best.user_attrs['dice1']:.4f}\")\n",
    "log(f\"Best Params = {best.params}\")\n",
    "\n",
    "with open(\"best_trial.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best_trial\": best.number,\n",
    "        \"dice2\": best.value,\n",
    "        \"dice1\": best.user_attrs['dice1'],\n",
    "        \"params\": best.params\n",
    "    }, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1891625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe(attrs=(\"params\", \"user_attrs\", \"value\"))\n",
    "df.to_csv(\"optuna_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18944bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0
         ],
         "y": [
          0.5766135610568542
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0
         ],
         "y": [
          0.5766135610568542
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate parameter importances with only a single trial.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m fig1 \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_optimization_history(study)\n\u001b[1;32m      2\u001b[0m fig1\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 4\u001b[0m fig2 \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_param_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m fig2\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      7\u001b[0m fig3 \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_parallel_coordinate(study)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:168\u001b[0m, in \u001b[0;36mplot_param_importances\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot hyperparameter importances.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m.. seealso::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m _imports\u001b[38;5;241m.\u001b[39mcheck()\n\u001b[0;32m--> 168\u001b[0m importances_infos \u001b[38;5;241m=\u001b[39m \u001b[43m_get_importances_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_importances_plot(importances_infos, study)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:82\u001b[0m, in \u001b[0;36m_get_importances_infos\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m     80\u001b[0m     target_name \u001b[38;5;241m=\u001b[39m metric_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target \u001b[38;5;28;01melse\u001b[39;00m target_name\n\u001b[1;32m     81\u001b[0m     importances_infos: \u001b[38;5;28mtuple\u001b[39m[_ImportancesInfo, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 82\u001b[0m         \u001b[43m_get_importances_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     n_objectives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mdirections)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:54\u001b[0m, in \u001b[0;36m_get_importances_info\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudy instance does not contain completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ImportancesInfo(\n\u001b[1;32m     48\u001b[0m         importance_values\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     49\u001b[0m         param_names\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     50\u001b[0m         importance_labels\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     51\u001b[0m         target_name\u001b[38;5;241m=\u001b[39mtarget_name,\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_param_importances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mitems())))\n\u001b[1;32m     59\u001b[0m importance_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/importance/__init__.py:111\u001b[0m, in \u001b[0;36mget_param_importances\u001b[0;34m(study, evaluator, params, target, normalize)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, BaseImportanceEvaluator):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluator must be a subclass of BaseImportanceEvaluator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m    113\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(res\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/importance/_fanova/_evaluator.py:89\u001b[0m, in \u001b[0;36mFanovaImportanceEvaluator.evaluate\u001b[0;34m(self, study, params, target)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the `study` is being used for multi-objective optimization, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease specify the `target`. For example, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`target=lambda t: t.values[0]` for the first objective value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0m distributions \u001b[38;5;241m=\u001b[39m \u001b[43m_get_distributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(distributions\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/importance/_base.py:69\u001b[0m, in \u001b[0;36m_get_distributions\u001b[0;34m(study, params)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_distributions\u001b[39m(study: Study, params: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseDistribution]:\n\u001b[1;32m     68\u001b[0m     completed_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, states\u001b[38;5;241m=\u001b[39m(TrialState\u001b[38;5;241m.\u001b[39mCOMPLETE,))\n\u001b[0;32m---> 69\u001b[0m     \u001b[43m_check_evaluate_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompleted_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m intersection_search_space(study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/optuna/importance/_base.py:114\u001b[0m, in \u001b[0;36m_check_evaluate_args\u001b[0;34m(completed_trials, params)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot evaluate parameter importances without completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completed_trials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot evaluate parameter importances with only a single trial.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate parameter importances with only a single trial."
     ]
    }
   ],
   "source": [
    "fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "fig1.show()\n",
    "\n",
    "fig2 = optuna.visualization.plot_param_importances(study)\n",
    "fig2.show()\n",
    "\n",
    "fig3 = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig3.show()\n",
    "\n",
    "fig4 = optuna.visualization.plot_contour(study)\n",
    "fig4.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
