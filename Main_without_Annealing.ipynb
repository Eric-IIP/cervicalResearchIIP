{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 16:15:04.315792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 16:15:04.986870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from numpy.core.numeric import NaN\n",
    "from MCtool.RFilter import gray\n",
    "from genericpath import exists\n",
    "from matplotlib import image\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.keras.backend import dtype\n",
    "from DeepLearning import LearnAndTest\n",
    "from Rpkg.Rfund.InputFeature import InputFeature\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Rpkg.Rfund import ReadFile, WriteFile\n",
    "from Rpkg.Rmodel import Unet, Mnet\n",
    "\n",
    "import Filtering\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import DeepLearning\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from Rpkg.Rfund.InputFeature import InputFeature\n",
    "from Rpkg.Rfund import ReadFile, WriteFile\n",
    "from Rpkg.Rmodel import Unet, Mnet\n",
    "\n",
    "from MCtool import RFilter, resultEval\n",
    "from DeepLearning import save_eval_result\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from transformations import ComposeDouble, FunctionWrapperDouble, create_dense_target, normalize_01\n",
    "from customdatasets import SegmentationDataSet1\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "from skimage.transform import resize\n",
    "\n",
    "#early stopping ãªã—\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version installed: 2.3.0+cu121\n",
      "CUDA version associated with PyTorch version: 12.1\n",
      "Version of cuDNN (CUDA Deep Neural Network library) being used by PyTorch8902\n",
      "CUDA is available: False\n",
      "Number of GPUs compatible with CUDA:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of GPUs compatible with CUDA:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Returns the name of the GPU at index 0\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName of the GPU at index 0: \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Returns the index of the current CUDA device being used\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent CUDA device index: \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()))\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:414\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:444\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "# è‡ªåˆ†ã®ç’°å¢ƒè¨­å®šãŒã†ã¾ãã„ã£ãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€ç‰¹ã«GPUã®å‹•ä½œ\n",
    "# Prints the version of PyTorch installed\n",
    "print('PyTorch Version installed: ' + torch.__version__)\n",
    "\n",
    "# Prints the version of CUDA associated with the installed PyTorch version\n",
    "print('CUDA version associated with PyTorch version: ' + torch.version.cuda)\n",
    "\n",
    "# Prints the version of cuDNN (CUDA Deep Neural Network library) being used by PyTorch\n",
    "print('Version of cuDNN (CUDA Deep Neural Network library) being used by PyTorch' + str(torch.backends.cudnn.version()))\n",
    "\n",
    "# Same as the line above\n",
    "print('CUDA is available: ' + str(torch.cuda.is_available()))\n",
    "\n",
    "# Returns the number of available CUDA-enabled GPUs\n",
    "print('Number of GPUs compatible with CUDA:' + str(torch.cuda.device_count()))\n",
    "\n",
    "# Returns the name of the GPU at index 0\n",
    "print('Name of the GPU at index 0: '  + str(torch.cuda.get_device_name(0)))\n",
    "\n",
    "# Returns the index of the current CUDA device being used\n",
    "print('Current CUDA device index: '  + str(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­éƒ¨åˆ†ï¼ˆprefixï¼‰ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚\n",
    "# å®Ÿéš›ãã‚Œãžã‚Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã¯é•ã†ã¨æ€ã†ã®ã§ã€å¿…é ˆã§ã¯ãªã„\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Extracts filenames in directory if they start with the prefix input \n",
    "\n",
    "\n",
    "Args/Parameters:\n",
    "\n",
    "    directory_path (string): The path of the dir (ex: /root/home/Documents/etc)\n",
    "    \n",
    "    prefix (string): Prefix of the file name (ex: 'Bo' is a prefix of 'Bone')\n",
    "\n",
    "Returns:\n",
    "\n",
    "    sorted_file_names (list of str): File names sorted in ascending order in the dir without extension ex: ['bone1', 'bone2', ...]\n",
    "\n",
    "Raises:\n",
    "\n",
    "    SomeError: ...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def file_names_with_prefix(directory_path, prefix):\n",
    "\n",
    "    # Initialize an empty list to store the file names without extensions\n",
    "    file_names_without_extension = []\n",
    "\n",
    "    # Loop through all files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        #Checking if the file in loop exists in the directory_path not sure how is this necessary\n",
    "        #??\n",
    "        if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "            # Check if the file name starts with the specified prefix\n",
    "            if filename.startswith(prefix):\n",
    "                # Get the file name without extension\n",
    "                name_without_extension, _ = os.path.splitext(filename)\n",
    "\n",
    "                # Append the file name (without extension) to the list\n",
    "                file_names_without_extension.append(name_without_extension)\n",
    "\n",
    "    # Sort the list of file names without extensions in ascending order\n",
    "    sorted_file_names = sorted(\n",
    "        file_names_without_extension,\n",
    "        key=lambda x: (x.split('-')[0], int(x.split('-')[1]))\n",
    "    )  # Modify this part based on your file naming convention\n",
    "\n",
    "    # Now you have a sorted list of file names with the specified prefix and without extensions\n",
    "    return sorted_file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/Eric/Downloads/imgNaming/processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/Eric/Downloads/imgNaming/processing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Call the function to rename the images\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mrename_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mrename_images\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename_images\u001b[39m(directory):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Get a list of all files in the directory\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Filter out only the image files\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     image_files \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/Eric/Downloads/imgNaming/processing'"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Custom Function renames all files in format N1-...\n",
    "# Only need to run it one time\n",
    "##############################\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def rename_images(directory):\n",
    "    # Get a list of all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Filter out only the image files\n",
    "    image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "    \n",
    "    # Sort the image files to ensure consistent naming\n",
    "    image_files.sort()\n",
    "    \n",
    "    # Initialize counter\n",
    "    counter = 1\n",
    "    \n",
    "    # Iterate through the image files\n",
    "    for filename in image_files:\n",
    "        # Open the image\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        with Image.open(image_path) as img:\n",
    "            # Rename the image file\n",
    "            new_filename = f\"N4-{counter}\" + os.path.splitext(filename)[1]\n",
    "            new_image_path = os.path.join(directory, new_filename)\n",
    "            \n",
    "            # Save the image with the new name\n",
    "            img.save(new_image_path)\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "\n",
    "# Specify the directory containing the images\n",
    "directory_path = \"/home/Eric/Downloads/imgNaming/processing\"\n",
    "\n",
    "# Call the function to rename the images\n",
    "rename_images(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/home/Eric/Downloads/TestD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: /home/eric/Documents/cervicalResearchIIP\n",
      "Data directory (original dir): /home/eric/Documents/cervicalResearchIIP/img_1006/original\n",
      "Feature img directory: /home/eric/Documents/cervicalResearchIIP/img_1006/feature\n",
      "Labeled img directory: /home/eric/Documents/cervicalResearchIIP/img_1006/labeled\n",
      "Annealing directory: /home/eric/Documents/cervicalResearchIIP/img_1006/original\n",
      "Result directory: /home/eric/Documents/cervicalResearchIIP/result/0424-Conv1x1-01\n",
      "Test result directory: /home/eric/Documents/cervicalResearchIIP/result_test/0424-Conv1x1-01\n",
      "['N1-1', 'N1-2', 'N1-3', 'N1-4', 'N1-5', 'N1-6', 'N1-7', 'N1-8', 'N1-9', 'N3-1', 'N3-2', 'N3-3', 'N3-4', 'N3-5', 'N3-6', 'N3-7', 'N3-8', 'N3-9']\n",
      "['N2-1', 'N2-2', 'N2-3', 'N2-4', 'N2-5', 'N2-6', 'N2-7', 'N2-8', 'N2-9']\n",
      "['N3-1', 'N3-2', 'N3-3', 'N3-4', 'N3-5', 'N3-6', 'N3-7', 'N3-8', 'N3-9']\n",
      "['N4-1', 'N4-2', 'N4-3', 'N4-4', 'N4-5', 'N4-6', 'N4-7', 'N4-8', 'N4-9']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# ã“ã“ã§ã€folderåã¨ã‹Pathã¨ã‹è‰²ã€…è¨­å®š\n",
    "\n",
    "# Setting the directory name, path and other settings\n",
    "\n",
    "# Define the root directory where your project is located\n",
    "# Defining a Path object for the project's root dir\n",
    "root_dir = Path(pathlib.Path.cwd())\n",
    "\n",
    "# result folder name\n",
    "date_str = '0424-Conv1x1-01'\n",
    "\n",
    "# Define the directories for different types of data\n",
    "# Concatenating the root dir to the different dataset dirs\n",
    "data_dir = str(root_dir / \"img_1006/original\")\n",
    "feature_dir = str(root_dir / \"img_1006/feature\") \n",
    "labeled_dir = str(root_dir / \"img_1006/labeled\")\n",
    "# annealing_img_dir = str(root_dir / \"img_1006/annealing_img\") # ç„¼ããªã¾ã—æ³•æ™‚ã«ä½¿ã†\n",
    "# annealing later, original for now\n",
    "annealing_img_dir = str(root_dir / \"img_1006/original\")\n",
    "result_dir = str(root_dir / \"result\" / date_str)\n",
    "test_result_dir= str(root_dir / \"result_test\" / date_str)\n",
    "\n",
    "# Making directories based on the path string result_dir and test_result_dir\n",
    "Path(result_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(test_result_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prints the paths of the dirs\n",
    "print('Root directory: ' + str(root_dir))\n",
    "print('Data directory (original dir): ' + str(data_dir))\n",
    "print('Feature img directory: ' + str(feature_dir))\n",
    "print('Labeled img directory: ' + str(labeled_dir))\n",
    "print('Annealing directory: ' + str(annealing_img_dir))\n",
    "print('Result directory: ' + str(result_dir))\n",
    "print('Test result directory: ' + str(test_result_dir))\n",
    "\n",
    "# Defining variables filename list of path str starts with the prefix format\n",
    "input_train = file_names_with_prefix(data_dir, 'N1-')\n",
    "input_name_val = file_names_with_prefix(data_dir, 'N2-')\n",
    "annealing_input_name = file_names_with_prefix(data_dir, 'N3-')\n",
    "input_train.extend(annealing_input_name)\n",
    "test_input_name = file_names_with_prefix(data_dir, 'N4-') \n",
    "\n",
    "# Prints the each data image name\n",
    "print(input_train)\n",
    "print(input_name_val)\n",
    "print(annealing_input_name)\n",
    "print(test_input_name)\n",
    "\n",
    "# Defining a var to store each list length\n",
    "len_train = len(input_train)\n",
    "len_val = len(input_name_val)\n",
    "len_test = len(test_input_name)\n",
    "len_annealing = len(annealing_input_name)\n",
    "\n",
    "\n",
    "# print(len(input_train))\n",
    "# print(len(input_name_val))\n",
    "# print(len(test_input_name))\n",
    "# print(len(annealing_input_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GRY_', 'NML1', 'NML2', 'NML3', 'TOP1', 'TOP2', 'TOP3', 'TOP4', 'SBLX', 'SBLY', 'SBLM', 'SBLD', 'SBL1', 'SBL2', 'SBL3', 'SBL4', 'LPL1', 'LPL2', 'MEA1', 'MEA2', 'GAU1', 'GAU2', 'MED1', 'MED2', 'LBP1', 'LBP2', 'LBP3', 'ETC1', 'ETC2', 'STC1', 'STC2', 'HGF_', 'NGP_', 'POS1', 'POS2', 'POS3', 'SOL_', 'EMB1', 'EMB2', 'EMB3', 'KNN1', 'KNN2', 'BLT1', 'BLT2', 'OOO_']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# ç‰¹å¾´ç”»åƒã®ç‰¹å¾´ä¸€è¦§ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—\n",
    "inputfeature_list = list(map(str, InputFeature))\n",
    "print(inputfeature_list)\n",
    "\n",
    "feature_num = len(inputfeature_list)\n",
    "print(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## é‡ã¿è¨ˆç®—ãªã—\n",
    "def CreateWeightImage(input_number):\n",
    "    label_dataset = []\n",
    "    arrDataset = []\n",
    "    for i in input_number:\n",
    "        label_path = os.path.join(labeled_dir, f\"{i}.png\")\n",
    "        input_originallabel = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # commented the binary label because the project has more labels than 2 \n",
    "        # _, binary_label = cv2.threshold(input_originallabel, 0, 255, cv2.THRESH_BINARY)\n",
    "        label_dataset.append(input_originallabel)\n",
    "\n",
    "    print(\"Number of label images:\", len(label_dataset))\n",
    "\n",
    "    for i in input_number:\n",
    "        # changed this part from 100 to 256\n",
    "        dataset_img = np.zeros((256, 256, feature_num), dtype=np.float32)\n",
    "\n",
    "        for m in range(feature_num):\n",
    "            feature_img_path = os.path.join(feature_dir, str(i), f\"{inputfeature_list[m]}.png\")\n",
    "            input_featureimg = cv2.imread(feature_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            dataset_img[:, :, m] = input_featureimg\n",
    "\n",
    "        arrDataset.append(dataset_img)\n",
    "\n",
    "    arrDataset = np.array(arrDataset)\n",
    "    print(\"dataset shape \", arrDataset.shape)\n",
    "    return arrDataset, label_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡ã¿ã‚’åŸºã¥ã„ã¦ã€MCç”»åƒã‚’ç”Ÿæˆã™ã‚‹\n",
    "def CreateWeightImageforShow(weight, input_number, index):\n",
    "    sum_weight = sum(weight)  # Calculate total weight\n",
    "\n",
    "    label_dataset = []\n",
    "    input_dataset = []\n",
    "    dataset_original = []\n",
    "\n",
    "    # Read label images\n",
    "    for i in input_number:\n",
    "        input_originallabel = cv2.imread(labeled_dir + \"/\" + str(i) + \".png\", flags=0)\n",
    "        label_dataset.append(input_originallabel)\n",
    "\n",
    "    print('Weight image for show, label length = ', len(label_dataset))\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(test_result_dir + \"/weightImage/\" + str(index), exist_ok=True)\n",
    "\n",
    "    # Generate weighted images\n",
    "    for i in input_number:\n",
    "        # Create a blank image to store the weighted image, using float type for accumulation\n",
    "        dataset_img = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "        input_originalimg = cv2.imread(data_dir + \"/\" + str(i) + \".png\")\n",
    "\n",
    "        dataset_original.append(input_originalimg)\n",
    "        for m in range(feature_num):\n",
    "            input_featureimg = cv2.imread(feature_dir + \"/\" + str(i) + \"/\" + inputfeature_list[m] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "            # Normalize the feature image\n",
    "            normalized_feature_img = cv2.normalize(input_featureimg.astype(np.float32), None, 0, 1, cv2.NORM_MINMAX)\n",
    "            # Accumulate the weighted feature image\n",
    "            dataset_img += normalized_feature_img[:, :, None] * (weight[m] / sum_weight)  # Convert 2D array to 3D array\n",
    "\n",
    "        # Normalize the accumulated image to the range 0-255\n",
    "        dataset_img = cv2.normalize(dataset_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        output_img = dataset_img.astype(np.uint8)  # Convert to uint8\n",
    "\n",
    "        input_dataset.append(output_img)\n",
    "        # Write to file\n",
    "        cv2.imwrite(f\"{test_result_dir}/weightImage/{index}/{i}.png\", output_img)\n",
    "\n",
    "    return input_dataset, label_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "N4-4\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n",
      "1 iteration\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Custom Function generates feature img\n",
    "##############################\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def read_images_from_directory(dir_path):\n",
    "    IMAGE_SIZE = 256\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Reads all image files from a directory and returns a list of images as NumPy arrays.\n",
    "    \n",
    "    :param dir_path: Path to the directory containing the images.\n",
    "    :param image_size: Size of the images (assumes square images).\n",
    "    \n",
    "    :return: img_list: List of images as NumPy arrays.\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "    fn_without_list = []\n",
    "\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(dir_path):\n",
    "        # Check if the file is an image file (you can add more extensions if needed)\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Construct the full path to the image\n",
    "            img_path = os.path.join(dir_path, filename)\n",
    "            \n",
    "            # Open the image and resize it to the desired size\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "            \n",
    "            # Convert the image to a NumPy array \n",
    "            img_array = np.asarray(img, dtype=np.float64)\n",
    "            \n",
    "            # Append the image array to the list\n",
    "            img_list.append(img_array)\n",
    "            # Gets the file name without extension for creating dir \n",
    "            filename_without_extension = os.path.splitext(filename)[0]\n",
    "            fn_without_list.append(filename_without_extension)\n",
    "    \n",
    "    return img_list, fn_without_list\n",
    "\n",
    "img_list, fn_without_list = read_images_from_directory(data_dir)\n",
    "print(len(fn_without_list))\n",
    "print(fn_without_list[0])\n",
    "for fn_wthout, img in zip(fn_without_list, img_list):\n",
    "    WriteFile.make_folder(feature_dir, '/' + fn_wthout)\n",
    "    fn_feature_list = []\n",
    "    filtered_img_list = []\n",
    "    for feature in InputFeature:\n",
    "        filtered_img= Filtering.single_image(img, feature)\n",
    "        filtered_img_list.append(filtered_img)\n",
    "        fn_feature_list.append(str(feature) + '.png')\n",
    "    WriteFile.save_images(os.path.join(feature_dir,fn_wthout), fn_feature_list, filtered_img_list)\n",
    "    print(\"1 iteration\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label images: 18\n",
      "dataset shape  (18, 256, 256, 45)\n",
      "Number of label images: 9\n",
      "dataset shape  (9, 256, 256, 45)\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "input_dataset,label_dataset = CreateWeightImage(input_train)\n",
    "input_dataset_val,label_dataset_val = CreateWeightImage(input_name_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_shapes(model, input_tensor):\n",
    "    def forward_hook(module, input, output):\n",
    "        print(f\"Layer: {module.__class__.__name__}\")\n",
    "        print(f\"Input shape: {str(input[0].shape)}\")\n",
    "        print(f\"Output shape: {str(output.shape)}\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        hook = layer.register_forward_hook(forward_hook)\n",
    "        hooks.append(hook)\n",
    "\n",
    "    print(\"Model Architecture:\")\n",
    "    print(model)\n",
    "\n",
    "    # Pass a dummy input tensor through the model to trigger the forward hooks\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "def preprocess(img: np.ndarray):\n",
    "    img = np.moveaxis(img, -1, 0)  # Change from [H, W, C] to [C, H, W]\n",
    "    img = normalize_01(img)  # Linear scaling to range [0-1]\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension [B, C, H, W]\n",
    "    img = img.astype(np.float32)  # Typecasting to float32\n",
    "    return img\n",
    "\n",
    "# postprocess function\n",
    "def postprocess(img: torch.tensor):\n",
    "    img = torch.argmax(img, dim = 1)  # Perform argmax to generate 1 channel\n",
    "    img = img * 255.0\n",
    "    img = img.cpu().numpy().astype(np.uint8)  # Send to CPU and transform to numpy.ndarray\n",
    "    # If batch_size > 1, you may need to loop through each batch and save them separately\n",
    "    # If batch_size == 1, you can remove the batch dimension to save a single image\n",
    "    img = np.squeeze(img)  # Remove batch dim and channel dim -> [H, W]\n",
    "    # img = re_normalize(img)  # Scale it to the range [0-255]\n",
    "\n",
    "    # If your image has multiple channels (C>1), like an RGB image, before saving with cv2.imwrite\n",
    "    # you need to ensure the channel order is [B, G, R] instead of the common [R, G, B]\n",
    "    # If C == 1, you can further reduce dimensions -> [H, W]\n",
    "    if img.shape[0] == 3:  # [C, H, W]\n",
    "        img = np.transpose(img, (1, 2, 0))  # [H, W, C]\n",
    "        img = img[:, :, ::-1]  # Convert RGB to BGR\n",
    "    elif img.shape[0] == 1:  # [C, H, W]\n",
    "        img = np.squeeze(img, 0)  # [H, W]\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlystoppingã‚ã‚Š\n",
    "# numpyå½¢å¼ã®ã¾ã¾å…¥åŠ›ã™ã‚‹ç”¨æ”¹è‰¯\n",
    "# å­¦ç¿’ã‚’è¡Œã„äºˆæ¸¬çµæžœç”»åƒã‚’å‡ºåŠ›ã™ã‚‹ã¨ã“ã¾ã§\n",
    "from customdatasets import SegmentationDataSet0\n",
    "from customdatasets import SegmentationDataSet1\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def Learn_EA(input_dataset,label_dataset,input_dataset_val,label_dataset_val,type_number):\n",
    "    # å¼•æ•°ã‚’è¿½åŠ ã—ã¦ä¿å­˜å…ˆã‚’æŒ‡å®šã™ã‚‹ã‚ˆã†æ”¹è‰¯\n",
    "    # try_number:ä½•å›žç›®ã®ç„¼ããªã¾ã—ã‹ã©ã†ã‹ã€‚ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«ä½¿ç”¨\n",
    "\n",
    "    # dataset training\n",
    "    dataset_train2 = SegmentationDataSet0(\n",
    "                                        #inputs=dataset_original,\n",
    "                                        inputs=input_dataset,\n",
    "                                        targets=label_dataset,\n",
    "                                        transform=transforms_training)\n",
    "\n",
    "    # dataloader training\n",
    "    dataloader_training2 = DataLoader(dataset=dataset_train2,\n",
    "                                     batch_size=2,\n",
    "                                     shuffle=False)\n",
    "    #ã‚‚ã¨ã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«true\n",
    "\n",
    "\n",
    "    batch = next(iter(dataloader_training2))\n",
    "  \n",
    "    x, y = batch\n",
    "    print(\"x.shape = \", x.shape)\n",
    "    print(\"x.min(), x.max() = \", x.min(), x.max())\n",
    "    print(\"y.shape = \", y.shape)\n",
    "    print(\"torch.unique(y) = \", torch.unique(y))\n",
    "\n",
    "\n",
    "    \n",
    "    # dataset training\n",
    "    dataset_val = SegmentationDataSet0(inputs=input_dataset_val,\n",
    "                                        targets=label_dataset_val,\n",
    "                                        transform=transforms_val)\n",
    "    #æ›¸ãæ›ãˆç®‡æ‰€\n",
    "    dataloader_val = DataLoader(dataset=dataset_val,\n",
    "                                     batch_size=2,\n",
    "                                     shuffle=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###earlystopping ã‚ã‚Š\n",
    "\n",
    "    from unet import UNet\n",
    "    from trainer2 import Trainer2 \n",
    "    from torch import nn #import torch \n",
    "    from pytorchtools import EarlyStopping\n",
    "    from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "    #device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda') \n",
    "    else: torch.device('cpu')\n",
    "\n",
    "    #model\n",
    "    model = UNet(in_channels=45,\n",
    "                 out_channels=13,\n",
    "                 n_blocks=4, \n",
    "                 start_filters=32,\n",
    "                 activation='relu',\n",
    "                 normalization='batch',\n",
    "                 conv_mode='same',\n",
    "                 dim=2,\n",
    "                 ).to(device)\n",
    "\n",
    "    # Assuming input_tensor is a sample input tensor with the correct shape (e.g., torch.randn(1, 3, 100, 100))\n",
    "    input_tensor = torch.randn(1, 45, 100, 100).to(device)  # Adjust the shape as needed\n",
    "    # print_model_shapes(model, input_tensor)\n",
    "\n",
    "\n",
    "    #criterion\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # criterion = BCEWithLogitsLoss()\n",
    "\n",
    "    #optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    #trainer\n",
    "    trainer = Trainer2(model=model, \n",
    "                       device=device, \n",
    "                       criterion=criterion, \n",
    "                       optimizer=optimizer, \n",
    "                       training_DataLoader=dataloader_training2,\n",
    "                       #validation_DataLoader=None, \n",
    "                       validation_DataLoader=dataloader_val, \n",
    "                       lr_scheduler=None, \n",
    "                       epochs=200, ##ðŸ˜ºðŸ˜ºðŸ˜ºðŸ˜º epoch=0, \n",
    "                       notebook=True)\n",
    "  \n",
    "    print(\"=======start training======\")\n",
    "    # start training\n",
    "    training_losses, validation_losses, lr_rates = trainer.run_trainer()\n",
    "    print(\"***************************\")\n",
    "\n",
    "    \n",
    "    \n",
    "    #ã“ã“ãŒã¡ã‚ƒã‚“ã¨ESã§æœ€é©ãªã‚¨ãƒãƒƒã‚¯æ•°ã®ãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã‚‹ã‹è¦æ¤œè¨¼\n",
    "    model_dir = os.path.join(\"model\", date_str)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_name = f\"model.pt\"\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"modelname:{model_name}ã‚’ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "\n",
    "    model_weights = torch.load(model_path)\n",
    "    model.load_state_dict(model_weights)\n",
    "    \n",
    "\n",
    "    # images = annealing_input_dataset\n",
    "    images = input_dataset_val\n",
    "\n",
    "    from inference import predict\n",
    "    from transformations import normalize_01, re_normalize\n",
    "    # predict the segmentation maps \n",
    "    output = [predict(img, model, preprocess, postprocess, device) for img in images]\n",
    "\n",
    "\n",
    "    for i in range(len(input_name_val)):\n",
    "        if(type_number == 0):\n",
    "            cv2.imwrite(os.path.join(result_dir, f'{input_name_val[i]}.png'), output[i])\n",
    "        elif(type_number == 1):\n",
    "            cv2.imwrite(os.path.join(test_result_dir, 'result_original', f'{input_name_val[i]}.png'), output[i])\n",
    "        elif(type_number == 2):\n",
    "            cv2.imwrite(os.path.join(test_result_dir, 'result_test', f'{input_name_val[i]}.png'), output[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label images: 18\n",
      "dataset shape  (18, 256, 256, 45)\n",
      "Number of label images: 9\n",
      "dataset shape  (9, 256, 256, 45)\n",
      "x.shape =  torch.Size([2, 45, 256, 256])\n",
      "x.min(), x.max() =  tensor(0.) tensor(1.)\n",
      "y.shape =  torch.Size([2, 256, 256])\n",
      "torch.unique(y) =  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m input_dataset,label_dataset \u001b[38;5;241m=\u001b[39m CreateWeightImage(input_train)\n\u001b[1;32m     19\u001b[0m input_dataset_val,label_dataset_val \u001b[38;5;241m=\u001b[39m CreateWeightImage(input_name_val)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mLearn_EA\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_dataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel_dataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 69\u001b[0m, in \u001b[0;36mLearn_EA\u001b[0;34m(input_dataset, label_dataset, input_dataset_val, label_dataset_val, type_number)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#model\u001b[39;00m\n\u001b[1;32m     61\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m             \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m             \u001b[49m\u001b[43mn_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m             \u001b[49m\u001b[43mstart_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m             \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m             \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m             \u001b[49m\u001b[43mconv_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 69\u001b[0m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Assuming input_tensor is a sample input tensor with the correct shape (e.g., torch.randn(1, 3, 100, 100))\u001b[39;00m\n\u001b[1;32m     72\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Adjust the shape as needed\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "## Test Learn_EA without annealing\n",
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble([\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "#è¿½åŠ ç®‡æ‰€ver3\n",
    "transforms_val = ComposeDouble([\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "# random seed\n",
    "random_seed = 0\n",
    "input_dataset,label_dataset = CreateWeightImage(input_train)\n",
    "input_dataset_val,label_dataset_val = CreateWeightImage(input_name_val)\n",
    "\n",
    "\n",
    "Learn_EA(input_dataset,label_dataset,input_dataset_val,label_dataset_val,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicecã®è¨ˆç®—\n",
    "def cal_Dice(dir, input_name):\n",
    "    # change the label count as your preference\n",
    "    Dice = [0] * 2\n",
    "    Count1 = [0] * 2 #äºˆæ¸¬çµæžœã®å„ãƒ©ãƒ™ãƒ«ã®è¦ç´ æ•°\n",
    "    Count2 = [0] * 2 #ãƒ©ãƒ™ãƒ«ç”»åƒã®\n",
    "    Count3 = [0] * 2 #æ­£è§£ã—ãŸç”»ç´ æ•°\n",
    "    unique_label = set()\n",
    "    for index in range(len(input_name)):\n",
    "        print('index = ', index)\n",
    "\n",
    "        img1 = cv2.imread(dir + '/' + input_name[index] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(labeled_dir + '/' + input_name[index] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "        # _, img2 = cv2.threshold(img2, 0, 255, cv2.THRESH_BINARY)\n",
    "        print(\"äºˆæ¸¬ç”»åƒ:\", dir  + '/' + input_name[index] + \".png\")\n",
    "        print(\"ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«:\", labeled_dir + '/' + input_name[index] + \".png\")\n",
    "        \n",
    "        # change the image array size to your need\n",
    "        for n in range(255):\n",
    "            for l in range(255):\n",
    "                value = img1[n,l]\n",
    "                unique_label.add(value)\n",
    "                if value == 0:\n",
    "                    Count1[0] += 1\n",
    "                else:\n",
    "                    Count1[1] = Count1[1] + 1\n",
    "                # Count1[value] = Count1[value] + 1\n",
    "                value2 = img2[n,l]\n",
    "                if value2 == 0:\n",
    "                    Count2[0] = Count2[0] + 1\n",
    "                else:\n",
    "                    Count2[1] = Count2[1] + 1\n",
    "                # Count2[value2] = Count2[value2] + 1\n",
    "\n",
    "                if(img1[n][l] == img2[n][l]):\n",
    "                    if value == 0:\n",
    "                        Count3[0] = Count3[0] + 1\n",
    "                    else:\n",
    "                        Count3[1] = Count3[1] + 1\n",
    "                    # Count3[value] = Count3[value] + 1\n",
    "\n",
    "\n",
    "    for i in range(2):\n",
    "        if(Count1[i]+Count2[i] != 0):\n",
    "            Dice[i] = (2*Count3[i])/(Count1[i] + Count2[i])\n",
    "    print(unique_label)\n",
    "    print('Count1 = ', Count1)\n",
    "    print('Count2 = ', Count2)\n",
    "    print('Count3 = ', Count3)\n",
    "    print('Dice = ', Dice)\n",
    "\n",
    "    return Dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# check the parameters\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mn_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m             \u001b[49m\u001b[43mstart_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m             \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m             \u001b[49m\u001b[43mconv_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 16\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, date_str)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_dir = \u001b[39m\u001b[38;5;124m\"\u001b[39m, model_dir)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "## Test of 1x1conv\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    torch.device('cpu')\n",
    "\n",
    "model = UNet(in_channels=45,  # check the parameters\n",
    "             out_channels=13,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "model_dir = os.path.join(\"model\", date_str)\n",
    "print(\"model_dir = \", model_dir)\n",
    "model_path = os.path.join(model_dir, \"model.pt\") # load the model\n",
    "model_weights = torch.load(model_path)\n",
    "model.load_state_dict(model_weights)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# create test dataset\n",
    "test_input_dataset, _ = CreateWeightImage(test_input_name) \n",
    "\n",
    "# convert to torch\n",
    "test_input_tensor = torch.from_numpy(test_input_dataset).float().to(device)\n",
    "\n",
    "from inference import predict\n",
    "from transformations import normalize_01, re_normalize\n",
    "# predict\n",
    "output = [predict(img, model, preprocess, postprocess, device) for img in test_input_dataset]\n",
    "\n",
    "# save images\n",
    "for i, output_img in enumerate(output):\n",
    "    image = np.ones((255, 255, 3), dtype=np.uint8) * 255\n",
    "    labels = np.unique(output_img)\n",
    "    for x in range(255):\n",
    "            for y in range(255):\n",
    "                # Get the pixel value (brightness)\n",
    "                pixel = output_img[x][y]\n",
    "               #  print(type(output_img))\n",
    "                if pixel == labels[0]:\n",
    "                     image[x, y] = [0,0,0]\n",
    "                elif pixel == labels[1]:\n",
    "                     image[x, y] = [2, 247, 68]\n",
    "                elif pixel == labels[2]:\n",
    "                     image[x, y] = [255, 0, 38]\n",
    "                elif pixel == labels[3]:\n",
    "                     image[x, y] = [234, 5, 250]\n",
    "                elif pixel == labels[4]:\n",
    "                     image[x, y] = [21, 0, 255]\n",
    "                elif pixel == labels[5]:\n",
    "                     image[x, y] = [0, 220, 245]\n",
    "                elif pixel == labels[6]:\n",
    "                     image[x, y] = [255, 98, 0]\n",
    "                elif pixel == labels[7]:\n",
    "                     image[x, y] = [0, 174, 255]\n",
    "                elif pixel == labels[8]:\n",
    "                     image[x, y] = [255, 0, 174]\n",
    "                elif pixel == labels[9]:\n",
    "                     image[x, y] = [255, 255, 255]\n",
    "                elif pixel == labels[10]:\n",
    "                     image[x, y] = [198, 119, 74]\n",
    "                elif pixel == labels[11]:\n",
    "                     image[x, y] = [251, 159, 164]\n",
    "                elif pixel == labels[12]:\n",
    "                     image[x, y] = [205, 240, 7]\n",
    "                else:\n",
    "                     print(\"There are more labels!\")\n",
    "    output_img = image\n",
    "    cv2.imwrite(os.path.join(test_result_dir, f\"{test_input_name[i]}.png\"), output_img)  # æ ¹æ®éœ€è¦è°ƒæ•´æ–‡ä»¶è·¯å¾„å’Œå‘½å\n",
    "    #print(valRange)\n",
    "\n",
    "\n",
    "Dice = cal_Dice(test_result_dir, test_input_name)\n",
    "\n",
    "df = pd.DataFrame(Dice)\n",
    "df = df.T\n",
    "df.to_csv(test_result_dir + \"/Dice.csv\", mode='a', header=False) # Diceã®çµæžœã‚’csvã«è¿½åŠ \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
